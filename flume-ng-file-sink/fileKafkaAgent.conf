# =============  Name the sources/sinks/channels  ==========
fileKafkaAgent.sources = r1
fileKafkaAgent.sinks = k1 k2
fileKafkaAgent.channels = c1 c2
 

# =============  Configure the source  ==========
fileKafkaAgent.sources.r1.type = spooldir 
fileKafkaAgent.sources.r1.spoolDir = d:\\data\\srcImage
fileKafkaAgent.sources.r1.fileHeader = true
fileKafkaAgent.sources.r1.basenameHeader = true
fileKafkaAgent.sources.r1.deletePolicy = immediate
fileKafkaAgent.sources.r1.deserializer = org.apache.flume.sink.solr.morphline.BlobDeserializer$Builder
fileKafkaAgent.sources.r1.batchSize = 1

 

# ==========  Configure the sink  ==========
fileKafkaAgent.sinks.k1.type = com.navinfo.flume.sink.FileSink
fileKafkaAgent.sinks.k1.directory = d:\\data\\desImage
fileKafkaAgent.sinks.k1.topic = dataFetched
fileKafkaAgent.sinks.k1.body = {"provider":"mapbar","type":"txt","dir":"d:\\data\\desImage"}
fileKafkaAgent.sinks.k1.preprocessor = com.navinfo.flume.sink.example.SimpleMessagePreprocessor
fileKafkaAgent.sinks.k1.kafka.metadata.broker.list = localhost:9092
fileKafkaAgent.sinks.k1.kafka.serializer.class = kafka.serializer.StringEncoder
 
fileKafkaAgent.sinks.k2.type = logger


# ==========  Use channels which buffers events in memory  ==========
fileKafkaAgent.channels.c1.type = memory
fileKafkaAgent.channels.c1.capacity = 1000
fileKafkaAgent.channels.c1.transactionCapacity = 100

fileKafkaAgent.channels.c2.type = memory
fileKafkaAgent.channels.c2.capacity = 1000
fileKafkaAgent.channels.c2.transactionCapacity = 100

 
# ==========  Bind the sources and sinks to the channels  ==========
fileKafkaAgent.sources.r1.channels = c1 c2
fileKafkaAgent.sinks.k1.channel = c1
fileKafkaAgent.sinks.k2.channel = c2